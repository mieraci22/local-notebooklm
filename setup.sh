#!/bin/bash
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Local NotebookLM â€” Setup Script
# For Mac Mini M4 (16GB) running macOS Tahoe
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

set -e

echo "ğŸ“š Local NotebookLM Setup"
echo "========================="
echo ""

# â”€â”€â”€ Check for Homebrew â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! command -v brew &> /dev/null; then
    echo "ğŸ“¦ Installing Homebrew..."
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
fi

# â”€â”€â”€ Install Ollama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if ! command -v ollama &> /dev/null; then
    echo "ğŸ¤– Installing Ollama..."
    brew install ollama
else
    echo "âœ… Ollama already installed"
fi

# â”€â”€â”€ Start Ollama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo "ğŸš€ Starting Ollama service..."
ollama serve &> /dev/null &
sleep 3

# â”€â”€â”€ Pull Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸ“¥ Pulling Llama 3.1 8B (~4.7GB)..."
ollama pull llama3.1:8b

echo ""
echo "ğŸ“¥ Pulling nomic-embed-text (~274MB)..."
ollama pull nomic-embed-text

# â”€â”€â”€ Verify Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸ” Verifying models..."
ollama list

# â”€â”€â”€ Python Environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸ Setting up Python environment..."

if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 not found. Install via: brew install python3"
    exit 1
fi

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
echo "ğŸ“¦ Installing Python packages..."
pip install --upgrade pip
pip install -r requirements.txt

# â”€â”€â”€ Quick Test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "ğŸ§ª Running quick test..."
python3 -c "
from langchain_ollama import ChatOllama, OllamaEmbeddings
import chromadb

# Test LLM
llm = ChatOllama(model='llama3.1:8b')
response = llm.invoke('Say hello in exactly 5 words.')
print(f'  LLM test: {response.content}')

# Test embeddings
embed = OllamaEmbeddings(model='nomic-embed-text')
vec = embed.embed_query('test')
print(f'  Embedding test: vector dim = {len(vec)}')

# Test ChromaDB
client = chromadb.Client()
print(f'  ChromaDB test: OK')

print('')
print('âœ… All systems operational!')
"

# â”€â”€â”€ Done â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "  ğŸ‰ Setup complete!"
echo ""
echo "  To start the app:"
echo "    source venv/bin/activate"
echo "    streamlit run app.py"
echo ""
echo "  Then open: http://localhost:8501"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
